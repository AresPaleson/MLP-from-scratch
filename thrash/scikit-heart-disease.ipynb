{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputation:\n",
      "Age                     0\n",
      "Gender                  0\n",
      "Blood Pressure          0\n",
      "Cholesterol Level       0\n",
      "Exercise Habits         0\n",
      "Smoking                 0\n",
      "Family Heart Disease    0\n",
      "Diabetes                0\n",
      "BMI                     0\n",
      "High Blood Pressure     0\n",
      "Low HDL Cholesterol     0\n",
      "High LDL Cholesterol    0\n",
      "Alcohol Consumption     0\n",
      "Stress Level            0\n",
      "Sleep Hours             0\n",
      "Sugar Consumption       0\n",
      "Triglyceride Level      0\n",
      "Fasting Blood Sugar     0\n",
      "CRP Level               0\n",
      "Homocysteine Level      0\n",
      "Heart Disease Status    0\n",
      "dtype: int64\n",
      "Encoded classes: ['No' 'Yes']\n",
      "Training the MLP model...\n",
      "\n",
      "Model Performance:\n",
      "Accuracy: 0.8065\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.81      1.00      0.89      1613\n",
      "         Yes       0.00      0.00      0.00       387\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.40      0.50      0.45      2000\n",
      "weighted avg       0.65      0.81      0.72      2000\n",
      "\n",
      "\n",
      "Performing hyperparameter tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\staff\\NN-from-scratch\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Lenovo\\staff\\NN-from-scratch\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Lenovo\\staff\\NN-from-scratch\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"heart_disease.csv\")\n",
    "\n",
    "# Separate numerical and categorical columns based on the data types you shared\n",
    "numerical_cols = ['Age', 'Blood Pressure', 'Cholesterol Level', 'BMI', 'Sleep Hours', \n",
    "                 'Triglyceride Level', 'Fasting Blood Sugar', 'CRP Level', 'Homocysteine Level']\n",
    "\n",
    "categorical_cols = ['Gender', 'Exercise Habits', 'Smoking', 'Family Heart Disease', \n",
    "                   'Diabetes', 'High Blood Pressure', 'Low HDL Cholesterol', \n",
    "                   'High LDL Cholesterol', 'Alcohol Consumption', 'Stress Level', \n",
    "                   'Sugar Consumption']\n",
    "\n",
    "target_col = 'Heart Disease Status'\n",
    "\n",
    "# Impute numerical columns\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "data[numerical_cols] = pd.DataFrame(\n",
    "    num_imputer.fit_transform(data[numerical_cols]),\n",
    "    columns=numerical_cols,\n",
    "    index=data.index\n",
    ")\n",
    "\n",
    "# Impute categorical columns\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "data[categorical_cols] = pd.DataFrame(\n",
    "    cat_imputer.fit_transform(data[categorical_cols]),\n",
    "    columns=categorical_cols,\n",
    "    index=data.index\n",
    ")\n",
    "\n",
    "# Impute target column if it has missing values\n",
    "if data[target_col].isna().any():\n",
    "    target_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    data[target_col] = target_imputer.fit_transform(data[target_col].values.reshape(-1, 1))\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(\"Missing values after imputation:\")\n",
    "print(data.isna().sum())\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = data.drop(target_col, axis=1)\n",
    "y = data[target_col]\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "print(f\"Encoded classes: {label_encoder.classes_}\")\n",
    "\n",
    "# Create preprocessing steps for scaling and encoding\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', MLPClassifier(hidden_layer_sizes=(100, 50), \n",
    "                               activation='relu',\n",
    "                               alpha=0.0001,\n",
    "                               learning_rate_init=0.001,\n",
    "                               learning_rate='adaptive',\n",
    "                               max_iter=1000, \n",
    "                               early_stopping=True,\n",
    "                               random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the MLP model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Decode predictions back to original labels for reporting\n",
    "y_test_original = label_encoder.inverse_transform(y_test)\n",
    "y_pred_original = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nModel Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_original, y_pred_original))\n",
    "\n",
    "# Perform a simpler hyperparameter tuning to find a better model\n",
    "param_grid = {\n",
    "    'classifier__hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
    "    'classifier__activation': ['relu', 'tanh'],\n",
    "    'classifier__alpha': [0.0001, 0.001]\n",
    "}\n",
    "\n",
    "print(\"\\nPerforming hyperparameter tuning...\")\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest parameters found by grid search:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "best_y_pred = best_model.predict(X_test)\n",
    "best_y_pred_original = label_encoder.inverse_transform(best_y_pred)\n",
    "\n",
    "# Evaluate the best model\n",
    "print(\"\\nBest Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, best_y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_original, best_y_pred_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"heart_disease.csv\")\n",
    "\n",
    "# Define columns\n",
    "numerical_cols = ['Age', 'Blood Pressure', 'Cholesterol Level', 'BMI', 'Sleep Hours', \n",
    "                 'Triglyceride Level', 'Fasting Blood Sugar', 'CRP Level', 'Homocysteine Level']\n",
    "\n",
    "categorical_cols = ['Gender', 'Exercise Habits', 'Smoking', 'Family Heart Disease', \n",
    "                   'Diabetes', 'High Blood Pressure', 'Low HDL Cholesterol', \n",
    "                   'High LDL Cholesterol', 'Alcohol Consumption', 'Stress Level', \n",
    "                   'Sugar Consumption']\n",
    "\n",
    "target_col = 'Heart Disease Status'\n",
    "\n",
    "# Impute numerical columns\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "data[numerical_cols] = pd.DataFrame(\n",
    "    num_imputer.fit_transform(data[numerical_cols]),\n",
    "    columns=numerical_cols,\n",
    "    index=data.index\n",
    ")\n",
    "\n",
    "# Impute categorical columns\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "data[categorical_cols] = pd.DataFrame(\n",
    "    cat_imputer.fit_transform(data[categorical_cols]),\n",
    "    columns=categorical_cols,\n",
    "    index=data.index\n",
    ")\n",
    "\n",
    "# Impute target column if missing values exist\n",
    "if data[target_col].isna().any():\n",
    "    target_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    data[target_col] = target_imputer.fit_transform(data[target_col].values.reshape(-1, 1))\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "data.to_csv(\"processed_heart_disease.csv\", index=False)\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(\"Missing values after imputation:\")\n",
    "print(data.isna().sum())\n",
    "print(\"Processed data saved as 'processed_heart_disease.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
